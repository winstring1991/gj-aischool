{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1주차과제.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMfIkQtr7eCUtG64xRn+dG4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/winstring1991/gj-aischool/blob/master/1%EC%A3%BC%EC%B0%A8%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9Ccufq6cdCY",
        "colab_type": "text"
      },
      "source": [
        "# 1. 언어\n",
        "\n",
        "![대체 텍스트](https://static.wixstatic.com/media/a27d24_b2061d324a954778b8d618b23e1231e2~mv2.jpg/v1/fill/w_360,h_270,al_c,q_90,usm_0.66_1.00_0.01/a27d24_b2061d324a954778b8d618b23e1231e2~mv2.webp)\n",
        "\n",
        "2016년 11월에 미국 구글이 온라인 번역 서비스 '구글 번역'의 번역 기술을 종전의 '통계 기계 번역'에서 '신경망 기계 번역'으로 전환하면서 약 30년 분량의 기술을 일거에 능가했다고 한다.\n",
        "\n",
        "신경망 기계 번역(Neural machine translation, NMT)은 일련의 단어의 가능성을 예측하기 위해 인공 신경망을 사용하는 기계 번역 접근 방법으로, 일반적으로 하나의 통합 모델에 문장들 전체를 모델링한다.\n",
        "\n",
        "신경망 기계 번역은 전통적인 통계적 기계 번역(SMT) 모델에 필요한 기억의 일부만이 필요하다. 더 나아가, 전통적인 번역 시스템과는 달리 신경망 기계 번역 모델의 모든 부분은 합동하여(단대단으로) 훈련을 받음으로써 번역 성능을 극대화한다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Odzk5vEtcjGM",
        "colab_type": "text"
      },
      "source": [
        "# 2. 음성\n",
        "\n",
        "![대체 텍스트](https://www.ddaily.co.kr/data/photos/cdn/20200414/art_1585707984.jpg)\n",
        "\n",
        "마음을 담다 KT 캠페인에서 태어날 때부터 청력을 잃어 말을 할 수 없었던 선천성 청각장애인인 김소희씨에게 본인의 목소리로 소통할 수 있도록 도움을 주었다. 김소희씨의 목소리를 복원하기 위해 먼저 가족들의 목소리를 녹음했다. 이어 동년배 사람들의 목소리를 분석하고 그녀의 구강구조를 파악해 목소리를 추론해나가는 기가지니 AI음성합성 기술을 통해 목소리가 완성됐다. \n",
        "\n",
        "P-TTS (Personalized-Text to Speech) 기술은 딥러닝 기술을 이용해 며칠간 수집한 음성 데이터만으로 특정 인물의 목소리를 합성해 낼 수 있다. 이 기술을 활용하면 단순히 문장을 발음하는 수준을 넘어 개인별 발화 패턴이나 억양까지 학습해 사람처럼 자연스럽게 말하는 것이 가능하다.\n",
        "\n",
        "그동안 딥러닝 기술을 활용해 연예인 목소리로 음성을 합성해 선보인 사례는 있지만, 제한된 문장만을 합성할 수 있거나 음성 합성 후 데이터를 정제하는 후처리 과정이 필요하다는 한계가 있었다. 반면 KT의 P-TTS 기술은 어떤 문장이라도 합성해 낼 수 있고 문장당 1초 내로 합성이 가능하며 후처리 과정이 필요하지 않다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCU1oHxMS-Y6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHF3iMhWcqVn",
        "colab_type": "text"
      },
      "source": [
        "# 3. 이미지\n",
        "![대체 텍스트](https://cdn.vox-cdn.com/thumbor/CMJs1AJyAmf27RUd2UI5WBSZpy4=/0x0:3049x2048/920x613/filters:focal(1333x1562:1819x2048):format(webp)/cdn.vox-cdn.com/uploads/chorus_image/image/63058104/fake_ai_faces.0.png)\n",
        "https://thispersondoesnotexist.com/ 라는 사이트가 있다. 세상에 존재하지 않지만 실제 존재하는 것 같은 사람을 보여주는 사이트다. 새로고침 할 때마다 새로운 얼굴이 등장하며 실제로 어딘가에 살아있을것 같은 사람의 얼굴이 매번 새롭게 생성된다. 이 사이트에서 사용한 모델은 GAN이라는 모델이다.\n",
        "\n",
        "GAN(Generative Adversarial Network)은 말 그대로 생성적 대립 신경망으로 '그럴듯한 가짜'를 만들어내는 모델과 생성자 모델과는 적대적인 구분자 모델을 만들어 구분자 모델에서 진짜와 가짜를 구분하는 방싯으로 적대적 학습을 시킨다.\n",
        "\n",
        "GAN은 학습이 불안정하기로 악명이 높다. 학습이 어렵다는 점은 GAN 모델이 다양한 곳에 응용되는 것을 가로막는 큰 장애물이었다. 이런 상황에서 수많은 실험 끝에 안정적인 학습이 가능한 GAN모델의 구조를 찾아낸 것이 DCGAN이다.\n",
        "\n",
        "DCGAN의 특징을 몇 가지 요약할 수 있다. 먼저, 선형 레이어와 풀링 레이어를 최대한 배제하고 합성곱과 'Transposed Convolution'으로 네트워크 구조를 만들었다. 또 배치정규화를 사용하고, 마지막 레이어를 제외하고 생성자의 모든 레이어에 ReLU를 사용했고, 구분자의 모든 레이어에 LeakyReLU를 사용했다. 또한, 가장 좋은 최적화 기법과 적절한 학습 속도 등을 찾아내기도 했다.\n",
        "\n",
        "이 외에도 cGAN, WGAN, EEGAN, BEGAN, CycleGAN, DiscoGAN, StarGAN, SRGAN, SEGAN 등 다양한 분야에 응용하려는 시도도 활발하다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5rXmmPicpOY",
        "colab_type": "text"
      },
      "source": [
        "# 4. 자율주행\n",
        "\n",
        "![대체 텍스트](http://www.aitimes.kr/news/photo/201910/14500_15320_3736.jpg)\n",
        "\n",
        "현대자동차와 기아자동차는 운전자의 주행성향에 맞는 부분 자율주행을 구현하는 기술인 SCC-ML을 세계 최초로 개발했다고 밝혔다.\n",
        "\n",
        "스마트 크루즈 컨트롤 SCC은 앞차와의 거리를 일정하게 유지해 운전자가 설정한 속도로 자율주행을 해주는 기능으로 ADAS(첨단 운전자보조 시스템)의 주요 기술 중 하나다. SCC-ML은 여기에 AI기술을 더해 운전자의 주행성향을 차가 스스로 학습해 SCC 작동 시 운전자와 거의 흡사한 패턴으로 자율주행을 해준다. \n",
        "\n",
        "기존의 SCC는 앞차와의 거리, 가속성 등의 주행패턴을 운전자가 직접 설정해야 했으며 조절되는 단계가 세밀하지 않아 운전성향을 고스란히 반영할 수 없었다. 예를 들어, 동일한 운전자라 하더라도 가속성향이 고속과 중속, 저속 구간에서 각각 다르지만 기존에는 이런 세부적인 설정을 변경할 수 없었다. 이 때문에 SCC가 운전자의 주행성향과 다를 경우 운전자는 이질감을 느끼거나 심할 경우 불안감 때문에 SCC 사용을 꺼리는 경우도 더러 있었다.\n",
        "\n",
        "SCC-ML의 원리는 먼저 전방카메라, 레이더 등의 센서가 다양한 운전상황에서 발생되는 정보를 지속적으로 수집해 ADAS의 두뇌격인 제어컴퓨터로 보낸다. 제어컴퓨터는 입력된 정보로부터 운전자의 주행습관을 추출해 종합적인 주행성향을 파악한다. 이때 인공지능 기술 중 하나인 머신러닝 알고리즘이 적용된다.\n",
        "\n",
        "주행성향은 크게 보면 앞차와의 거리, 가속성(얼마나 신속하게 가속하는지), 반응성(주행환경에 얼마나 민첩하게 반응하는지) 세 가지로 나눌 수 있으며 거기에 더해 다양한 속도와 주변 차량과의 거리 조건을 모두 고려했다.\n",
        "\n",
        "주행성향에 대한 정보는 센서를 통해 계속 업데이트되기 때문에 운전자의 최근 성향을 반영할 수 있다. 또 안전운전을 크게 벗어난 주행성향은 따르지 않도록 설정돼 있어서 신뢰성을 높였다. 또 SCC-ML은 자동 차로 변경 기능을 포함하고 있는 HDA II와 함께 적용돼 자율주행 레벨 2을 넘어선 레벨 2.5 수준을 구현한다.\n",
        "\n",
        "\n"
      ]
    }
  ]
}